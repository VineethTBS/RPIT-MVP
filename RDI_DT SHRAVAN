import datetime
import json
from openpyxl import load_workbook
import openpyxl
import pandas as pd
import numpy as np
from openpyxl.utils import get_column_letter
import formulas
import dill
import string
# read file
import boto3
import os
from pathlib import Path
import time
from decimal import Decimal
from pathlib import Path
import sys



class Ingestion:
    

        
    def __init__(self,file_name):
     self.file_name = file_name




    def col2num(self,col):
        num = 0
        for c in col:
            if c in string.ascii_letters:
                num = num * 26 + (ord(c.upper()) - ord('A')) + 1
        return num

    def find_row_with_highest_count(self,ws):    
        index = 1
        index_dict=dict()
        for row in ws:
            count = sum(cell.value is not None for cell in row)
        
            index_dict[index] = count
            index+=1
            if index >= ws.max_row*0.05:
                break
    
        max_key = max(index_dict, key=index_dict.get)
      
        return max_key
        
   
    
    def initialize_df_column_metadata(self,column_name,has_formula,col_index,col_value):
        column_dict = dict()
        column_dict["ColumnName"] = column_name
        column_dict["ColValue"] = col_value
        column_dict["IsFormula"] = has_formula
        column_dict["ColLetter"] = get_column_letter(col_index)
        return column_dict
    def initialize_df_metadata(self,ws):
        df_dict = dict()
        df_dict["ValidColor"] = set()
        df_dict["ColumnData"] = list()
        df_dict["FormulasCount"] = 0
        df_dict["ColCount"] = 0
        return df_dict
    
    def Find_Input_Output_Dfs(self,current_df):
        start_time = time.time()
        df_meta_data=self.process(current_df,ws)
        temp_df = pd.DataFrame(df_meta_data)
        #temp_df.to_json('data.json', orient='records', lines=True)
        template_df =  temp_df.sort_values([ 'FormulasCount'],ascending=False).iloc[0].to_dict()
        #template_df.to_json('test.json', orient='records', lines=True)
        temp_df.drop( df_meta_data.index(template_df),inplace=True)
        input_data_frame =  temp_df.sort_values(['ColCount', 'FormulasCount'],ascending=False).iloc[0].to_dict()
        end_time = time.time()
        print(f"find_row_with_highest_count: {end_time - start_time} seconds")

        return template_df, input_data_frame

        
    
    def extract_col_letters(self,input_data_frame, template_df):

        input_column_data = input_data_frame.get('ColumnData', [])
        if isinstance(input_column_data, str):
            input_column_data = eval(input_column_data)
        if isinstance(template_column_data, str):
            template_column_data = eval(template_column_data)
        result = {
            'input_first_index': None,
            'input_last_index': None,
            'template_df_first_index': None,
            'template_df_last_index': None
        }
        if input_column_data:
             result['input_first_index'] = input_column_data[0].get('ColLetter')
             result['input_last_index'] = input_column_data[-1].get('ColLetter')
        if template_column_data:
            result['template_df_first_index'] = template_column_data[0].get('ColLetter')
            result['template_df_last_index'] = template_column_data[-1].get('ColLetter')
            
        return result

    def valid_color_check(self, col_index, max_key, current_df, ws):
        cell_fill = ws[max_key][col_index].fill
        if cell_fill is not None and cell_fill.start_color is not None:
            color_index = str(cell_fill.start_color.index)
            if (color_index in current_df["ValidColor"]) or (len(current_df["ValidColor"]) == 0):
                if color_index != '00000000':
                    return True
        return False
   

    
    

    def process(self, current_df,ws):
        start_time = time.time()

        df_meta_data = list()
        col_index = 0
        max_key = self.find_row_with_highest_count(ws)
        

        while col_index<ws.max_column:

            has_formula = False
            if ws[max_key][col_index].value == None:
                if  len(current_df["ColumnData"]) == 0:
                    
                    col_index += 1    
                    
                else:
                    if self.valid_color_check(col_index,max_key,current_df,ws):
                        current_df["ValidColor"].add( str(ws[max_key][col_index].fill.start_color.index ))
                        if str(ws[max_key+1][col_index].value).startswith('='):
                            current_df["FormulasCount"] += 1
                            has_formula = True
                        current_df["ColumnData"].append(self.initialize_df_column_metadata(ws[max_key][col_index].value,has_formula,col_index+1,str(ws[max_key+1][col_index].value)))
                        
                        current_df["ColCount"] += 1
                        col_index += 1
                        
                    else:
                        df_meta_data.append(current_df)
                        current_df = self.initialize_df_metadata(ws)
                        col_index += 1
                        

                        
            else :
                current_df["ValidColor"].add( str(ws[max_key][col_index].fill.start_color.index ))
                if str(ws[max_key+1][col_index].value).startswith('='):
                    current_df["FormulasCount"] += 1
                    has_formula = True
                current_df["ColumnData"].append(self.initialize_df_column_metadata(ws[max_key][col_index].value,has_formula,col_index+1,str(ws[max_key+1][col_index].value)))
                current_df["ColCount"] += 1
                col_index += 1
    
            
        if len(current_df["ColumnData"]) != 0:
            df_meta_data.append(current_df)
        end_time = time.time()
        print(f"Process: {end_time - start_time} seconds")
        return df_meta_data

    def process_all_sheets_except_active(self, file_name):
        all_sheets_meta_data = []
        workbook = load_workbook(filename=file_name, read_only=True)
        active_sheet_name = workbook.active.title

        for sheet_name in workbook.sheetnames:
            if sheet_name != active_sheet_name: 
                ws = workbook[sheet_name]
                current_df = self.initialize_df_metadata(ws)  
                sheet_meta_data = self.process(current_df, ws)
                if isinstance(sheet_meta_data, list) and all(isinstance(item, dict) for item in sheet_meta_data):
                    sheet_meta_data_converted = [{k: list(v) if isinstance(v, set) else v for k, v in item.items()} for item in sheet_meta_data]
                    for item in sheet_meta_data_converted:
                        if "ValidColor" in item:
                            del item["ValidColor"]
                else:
                    sheet_meta_data_converted = sheet_meta_data
                all_sheets_meta_data.append({"SheetName": sheet_name, "MetaData": sheet_meta_data_converted})
        all_sheets_meta_data = json.loads(json.dumps(all_sheets_meta_data), parse_float=Decimal)
        return all_sheets_meta_data
            
    
    def getDynamo(self):
        return boto3.resource(
        'dynamodb',
        aws_access_key_id     = 'ASIA4C44A42VCQH3HPQH',
        aws_secret_access_key = '1GcfZbxc0Wt9ZCUckEnKOiGRgVe+GnTsrfGvPbLv',
        aws_session_token     = 'FwoGZXIvYXdzEKL//////////wEaDF6e7S7Z7Kntq9hb2yKSAvBcNiI5VisY/Czg3JQezFrf8z6rYU54FdGYP2ZSfr3qRgXbujXx/kBmqh9AU+33oGU/rC4OntgF4XB2JQO9cvpASKgAGIeZmx+OYCh5WCHetUz65SR5xojIJxRA3ocDC9U6PWNe7LCAPPw28x5lr4V+FVVK0tlwGp4+nTF80VRZi72RFg782ZwE8DCKyYIEBbNJB7SGFHkhw73vtQtWhJbqOwso8M0wPZzfDazsIAQcBykEtZbpM8icYt4CQQ8Ukkw6IEhfPcD33j2W64YrvV6MgsGOJGkqE3o7B20vGO4en907yRoSLbSEa36U2HDp/3qkFu5GgPTxQDQOwZlNz7cSkvs6+AkjJFB82AoiLD8bwJco8bW+tAYyKwvyT8XxEkFPCLXCZ7gIAR1I6kKOkSoj14rsvZuRMEU18TM8xyQewXswT3Y=',

        region_name="us-east-1")


    def put_data(self):
        start_time = time.time()
        dyn_resource = self.getDynamo()
        table = dyn_resource.Table("psl-db-data-mapper-lab")
        template_df, input_data_frame = self.Find_Input_Output_Dfs(current_df)
        all_sheets_meta_data=self.process_all_sheets_except_active(file_name)
        input_data_frame = {k: v for k, v in input_data_frame.items() if k != 'ValidColor'}
        template_df = {k: v for k, v in template_df.items() if k != 'ValidColor'}
        

        

        table.put_item(Item={
            'inputdata': input_data_frame,
            'templatedata': template_df,
            'dealId': Path(file_name).stem,
            'All_Sheets_Meta_Data': all_sheets_meta_data,
            
        })
        end_time = time.time() 
        print(f"Find_Input_Output_Dfs: {end_time - start_time} seconds")
        
    def createFunctionObject(self,formula,sheet_name):
        parameterIndex = 0
        to_check_sheets = [sheet for sheet in wb.sheetnames if sheet.lower()!=sheet_name.lower() ]
        isConstant = False
        vLookupHash = None
        if len(str(formula))==0 or str(formula)[0]!='=':
            isConstant = True
            ConstantVal = formula
            return {"isConstant": isConstant,"ConstantVal": ConstantVal}
        func = formulas.Parser().ast(formula)[1].compile()
        
        parameters = []
        for parameter in func.inputs:
            isSelfRef = False
            isVlookup = False
            vLookupHash = None
            if   str(parameter).split('!')[0].upper().replace("'","") in (sheet.upper() for sheet in to_check_sheets):
                isVlookup = True
                print(str(parameter).split('!')[1].split(":"))
            
                start,end = str(parameter).split('!')[1].split(":")
                
                vLookupHash = dill.dumps(  self.getVlookup(str(parameter).split('!')[0].replace("'",""),start.replace('$',''),end.replace('$','')))

                ##to do: vlook up logic
            elif  self.check_if_parameter_in_input(str(parameter)) :   
                parameterIndex = parameter
            elif self.check_if_parameter_in_template(str(parameter)):
                isSelfRef = True
                parameterIndex = parameter
            parameters.append({"parameterIndex":parameterIndex,"vlookUpHash":None,"isSelfRef":isSelfRef,"isVlookup":isVlookup})
        return {"parameter": parameters,"isConstant":isConstant}
    def getVlookup(self,sheet_name,start,end):
    # wb = load_workbook(BytesIO(self.fileData), 
    #             read_only=True)
        indx = next(i for i,v in enumerate(wb.sheetnames) if v.lower() == str(sheet_name).lower())
    
        ws = wb.worksheets[indx]

        data_rows = []
        if  start == end:
            for row in ws[start:end]:
                
                data_rows.append(row.value)
    # Read the cell values into a list of lists
        
        else:
            for row in ws[start:end]:
                data_cols = []
                for cell in row:
                    data_cols.append(cell.value)
                data_rows.append(data_cols)

    # Transform into dataframe
        df = pd.DataFrame(data_rows)
        return df

    def check_if_parameter_in_input(self,index):
        if (self.col2num(index) >=self.col2num(self.input_data_frame['ColumnData'][0]["ColLetter"])) and  (self.col2num(index) <=self.col2num(self.input_data_frame['ColumnData'][-1]["ColLetter"])):
            return True
        return False

    def check_if_parameter_in_template(self,index):
        if (self.col2num(index) >=self.col2num(self.template_df['ColumnData'][0]["ColLetter"])) and  (self.col2num(index) <=self.col2num(self.template_df['ColumnData'][-1]["ColLetter"])):
            return True
        return False
    

    def PrimaryDealData(self): 
            inputId = str(datetime.datetime.now().strftime('%Y%m%d%H%M%S%f')) # This is the input id of the primary deal data
            print(inputId)
            # Corrected approach to get all rows in columns BP to FA
            #output_data_rows = []
            # for row in ws.iter_rows(min_row=self.find_row_with_highest_count(), min_col=127, max_col=145, max_row=self.find_row_with_highest_count()+2, values_only=True):
            #     output_data_rows.append(row)
            # dfOutput = pd.DataFrame(output_data_rows)
            # new_header = dfOutput.iloc[0]
            # dfOutput = dfOutput[1:]
            # dfOutput.columns = new_header
            # dfOutputColumns=list(dfOutput.columns)
            # print(dfOutputColumns)
            
            FunctionList = []
            ColumnfunctionList = []
            for col in self.template_df(current_df)["ColumnData"]:
               
               col["columnFunctionData"] = self.createFunctionObject(col["ColValue"],wb.active.title)
            dyn_resource = self.getDynamo()
            try:
                table = dyn_resource.Table("psl-db-data-mapper-lab")
                print("Size")
                print(sys.getsizeof(FunctionList))

                table.put_item(
                        Item={
                           # 'Id': str(inputId),
                            #'EngineUsed': "Excel",
                            #'poolId': self.poolId,
                            #'dealId':self.dealId,

                            #'inputColumns':self.ExtractColumns(),
                            #'outputColumns': dfOutputColumns,
                            'columnFunctionData': ColumnfunctionList})
            except Exception as err:
             print(err) 

file_name = r"Apollo Series 2023-1 from_Suncorp MILAN Template - HL edit .xlsm"
wb = load_workbook(filename=file_name, read_only=True)  # Optimized loading
ws = wb.active
#ws=wb["CODE"]
current_df = Ingestion(file_name).initialize_df_metadata(ws)
Ingestion(file_name).Find_Input_Output_Dfs(current_df)
Ingestion(file_name).PrimaryDealData()
#Ingestion(file_name).put_data()
#Ingestion(file_name).put_data()
print("Data Ingested Successfully")


    
